{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "with open('data.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        rows.append(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.......855.442......190..................................969..........520.......59.............................................172..........']\n"
     ]
    }
   ],
   "source": [
    "print(rows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23163/3724317144.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sc = np.array(sc)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "symbols = set(r\"\"\"`~!@#$%^&*()_-+={[}}|\\:;\"'<,>?/\"\"\")\n",
    "sc = []\n",
    "nums =  []\n",
    "for idx, row in enumerate(rows):\n",
    "    row = row[0]\n",
    "    nums.append(dict((m.start(), int(m.group())) for m in re.finditer(r'\\d+', row)))\n",
    "    sc.append([index for index, char in enumerate(row) if char in symbols])\n",
    "\n",
    "sc = np.array(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "partsum = 0\n",
    "for idx, row in enumerate(nums):\n",
    "    \n",
    "    for item in row:\n",
    "        \n",
    "        ids = np.arange(item-1,item+1+len(str(row[item ])), 1, dtype=int)\n",
    "        \n",
    "        \n",
    "        if idx==0:\n",
    "            arr = np.concatenate((sc[0], sc[1]), axis=None)\n",
    "            if any(np.isin(arr, ids)):\n",
    "                partsum += row[item]\n",
    "        elif idx==len(nums)-1:\n",
    "            arr = np.concatenate((sc[idx-1], sc[idx]), axis=None)\n",
    "            if any(np.isin(arr, ids)):\n",
    "                partsum += row[item]\n",
    "        else:\n",
    "            arr = np.concatenate((sc[idx-1], sc[idx], sc[idx+1]), axis=None)\n",
    "            if any(np.isin(arr, ids)):\n",
    "                partsum += row[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531932"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23163/830642123.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sc = np.array(sc)\n"
     ]
    }
   ],
   "source": [
    "symbols = set(r\"*\")\n",
    "sc = []\n",
    "nums =  []\n",
    "for idx, row in enumerate(rows):\n",
    "    row = row[0]\n",
    "    nums.append(dict((m.start(), int(m.group())) for m in re.finditer(r'\\d+', row)))\n",
    "    sc.append([index for index, char in enumerate(row) if char in symbols])\n",
    "\n",
    "sc = np.array(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "11\n",
      "13\n",
      "13\n",
      "13\n",
      "14\n",
      "14\n",
      "15\n",
      "15\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "17\n",
      "17\n",
      "18\n",
      "19\n",
      "19\n",
      "19\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "22\n",
      "22\n",
      "22\n",
      "23\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "28\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "30\n",
      "30\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "33\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "36\n",
      "36\n",
      "37\n",
      "37\n",
      "37\n",
      "38\n",
      "38\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "41\n",
      "42\n",
      "42\n",
      "43\n",
      "43\n",
      "43\n",
      "44\n",
      "44\n",
      "44\n",
      "45\n",
      "45\n",
      "46\n",
      "46\n",
      "47\n",
      "47\n",
      "47\n",
      "48\n",
      "48\n",
      "49\n",
      "49\n",
      "49\n",
      "50\n",
      "51\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "54\n",
      "54\n",
      "55\n",
      "55\n",
      "56\n",
      "56\n",
      "56\n",
      "56\n",
      "57\n",
      "59\n",
      "59\n",
      "60\n",
      "61\n",
      "61\n",
      "61\n",
      "61\n",
      "62\n",
      "62\n",
      "62\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "65\n",
      "65\n",
      "66\n",
      "66\n",
      "67\n",
      "67\n",
      "69\n",
      "69\n",
      "69\n",
      "69\n",
      "71\n",
      "71\n",
      "72\n",
      "73\n",
      "73\n",
      "73\n",
      "74\n",
      "74\n",
      "74\n",
      "75\n",
      "75\n",
      "76\n",
      "76\n",
      "77\n",
      "78\n",
      "78\n",
      "78\n",
      "78\n",
      "78\n",
      "78\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "81\n",
      "82\n",
      "82\n",
      "83\n",
      "83\n",
      "84\n",
      "84\n",
      "84\n",
      "85\n",
      "85\n",
      "85\n",
      "86\n",
      "86\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "89\n",
      "90\n",
      "90\n",
      "91\n",
      "91\n",
      "92\n",
      "92\n",
      "93\n",
      "93\n",
      "95\n",
      "95\n",
      "95\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "98\n",
      "98\n",
      "98\n",
      "99\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "102\n",
      "102\n",
      "102\n",
      "103\n",
      "103\n",
      "104\n",
      "104\n",
      "104\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "106\n",
      "107\n",
      "107\n",
      "107\n",
      "108\n",
      "108\n",
      "109\n",
      "109\n",
      "109\n",
      "110\n",
      "110\n",
      "110\n",
      "111\n",
      "112\n",
      "112\n",
      "112\n",
      "113\n",
      "113\n",
      "114\n",
      "114\n",
      "115\n",
      "115\n",
      "115\n",
      "117\n",
      "118\n",
      "118\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "120\n",
      "120\n",
      "121\n",
      "121\n",
      "122\n",
      "122\n",
      "122\n",
      "123\n",
      "123\n",
      "123\n",
      "124\n",
      "125\n",
      "125\n",
      "126\n",
      "126\n",
      "126\n",
      "126\n",
      "126\n",
      "127\n",
      "127\n",
      "127\n",
      "127\n",
      "128\n",
      "128\n",
      "129\n",
      "129\n",
      "129\n",
      "129\n",
      "129\n",
      "129\n",
      "130\n",
      "130\n",
      "130\n",
      "130\n",
      "131\n",
      "131\n",
      "131\n",
      "131\n",
      "131\n",
      "132\n",
      "133\n",
      "133\n",
      "133\n",
      "134\n",
      "134\n",
      "135\n",
      "135\n",
      "135\n",
      "136\n",
      "136\n",
      "136\n",
      "136\n",
      "136\n",
      "137\n",
      "137\n",
      "137\n",
      "137\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "gearproduct = 0\n",
    "number_ids = [[] for _ in range(0,len(nums))]\n",
    "values_ids = [[] for _ in range(0, len(nums))]\n",
    "for idx, row in enumerate(nums):\n",
    "    for item in row:\n",
    "        number_ids[idx].extend(np.arange(item-1,item+1+len(str(row[item])), 1, dtype=int))\n",
    "        values_ids[idx].extend(np.full(len(np.arange(item-1,item+1+len(str(row[item])))) ,row[item]))\n",
    "\n",
    "for idx, row in enumerate(sc):\n",
    "    for ii, item in enumerate(row):\n",
    "        if idx==0:\n",
    "            arr = np.concatenate((number_ids[0], number_ids[1]), axis=None)\n",
    "            val_arr = np.concatenate((values_ids[0], values_ids[1]), axis=None)\n",
    "            if np.sum(np.isin(arr, item)) == 2:\n",
    "                gearproduct += np.product(values_ids[idx][np.where(np.isin(arr, item))])\n",
    "        elif idx==len(nums)-1:\n",
    "            arr = np.concatenate((number_ids[idx-1], number_ids[idx]), axis=None)\n",
    "            val_arr = np.concatenate((values_ids[idx-1], values_ids[idx]), axis=None)\n",
    "            \n",
    "            if np.sum(np.isin(arr, item)) == 2:\n",
    "                gearproduct += np.product(values_ids[idx][np.where(np.isin(arr, item))])\n",
    "        else:\n",
    "            arr = np.concatenate((number_ids[idx-1], number_ids[idx], number_ids[idx+1]), axis=None)\n",
    "            val_arr = np.concatenate((values_ids[idx-1], values_ids[idx], values_ids[idx+1]), axis=None)\n",
    "            if np.sum(np.isin(arr, item)) == 2:\n",
    "                print(idx)\n",
    "                id = np.where(np.isin(arr, item))[0].tolist()\n",
    "                gearproduct += val_arr[id[0]]*val_arr[id[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73646890"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gearproduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "855"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_ids[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
